<!--<!doctype html>
<html>-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<head>
 <link rel="Shortcut Icon" href="./logo/shengdanmilu.png" sizes=16x16  type="image/x-icon" />
 <link rel="Bookmark" href="./logo/shengdanmilu.png" sizes=16x16 type="image/x-icon" />
<!--<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">-->
  <title>Yang Wang</title>
	<style>
@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 650px; margin : 20px auto; }
.container { width : 700px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 40px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 10px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 0px; font-weight: normal;}
.publication strong a { color : #0000A0; }
.publication .links { position :relative ; top : 10px }
.publication .links a { margin-right : 5px; font-size: 15px; font-weight: normal}
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
li, ul {font-weight: normal;}
</style>
<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="stylesheets/pygment_trac.css">
<meta name="viewport" content="width=device-width">
<script async="" src="./analytics.js"></script>
</head>
<body>
<div class="wrapper">
<header>
<h7>Yang Wang</h7><br><br>
<div>
<img src="img/wangyang.png" border="0" width="90%"><br></div><br>

  
<p>
<small>üìç Changan, XiAn China</small><br>
<small>üìßywang120@chd.edu.cn</small><br>
	
<!--<a href="https://github.com/Li-Chongyi/" target="_blank">[GitHub]</a>-->  
<!--<a href="http://dblp.uni-trier.de/pers/hd/l/Li:Chongyi" target="_blank">[DBLP]</a>  <br>-->
<a href="https://scholar.google.com/citations?user=7TFKCpQAAAAJ&hl=en" target="_blank">[Google Scholar]</a> <br>
<!-- <a href="https://github.com/starttomo" target="_blank">[&pi; Research Group]</a> -->
</p> <br>
	
	
<p class="view"><a href="https://Yang-CHD2025.github.io">Homepage</a></p>
<p class="view"><a href="htmlTest.html">Publications</a></p>
<!-- ËøôÈáåÊòØÂ∑¶‰æß‰ø°ÊÅØÊ†èÈÉ®ÂàÜÔºåpi group Ê≤°ÂÅöÔºåpublicationÂæÖÂÅö -->
<!--<p class="view"><a href="datasets.html">Datasets</a></p>-->

	
<!--<p class="view"><a href="sub_projects.html">Projects</a></p>-->
</header>

<section>

<h2>
<a id="Biography-page" class="anchor" href="#biography-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to Yang Wang(ÁéãÊ¥ã)'s Homepage</h2>
<div style="text-align: justify; display: block; margin-right: auto;">
<p>
<br>I am Wang Yang, an associate professor and Ph.D. supervisor at Chang'an University, 
      recognized as a top-tier young talent. My research focuses on deep learning and computer vision, 
      with numerous publications in top conferences and journals like CVPR, NeurIPS, and TIP. 
      I also actively collaborate with industry partners including Huawei.
</p>




<!--
<h2>
<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Open Positions:</h2>
<br><p><font color="red">I am looking for several Postdoctoral Fellows at Nankai University (work in Tianjin or Shenzhen). The application deadline is 11 March 2024. If you wanna have a try, please drop me an email. </font></p></br>
</ul>
<br>	
<br><p><font color="blue">I am looking for PhD students and Master students who want to conduct
research and develop advanced deep learning algorithms for image and video enhancement and restoration, computational imaging, and image signal processor to join my research group at Nankai University (2023 Fall or 2024 Fall). I am also recruiting Research Associates and Final Year Project students.</font></p></br>
</ul>
<br>	
-->

<!-- <hr /> 
</p>
<h2>
<a id="reaserch-page" class="anchor" href="#reaserch-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Research Interests:</h2> -->

<!-- <ul>
<div style="text-align: justify; display: block; margin-right: auto;">
<p>My primary reseach interests include artificial intelligence, machine learning, computer vision, and image processing, particularly in the domains of 
  <li><strong>Image and Video Restoration and Enhancement</strong></li> <br/>
	The purpose is to develop algorithms to process an image or video so that result is more suitable than original image or video for specific application. The specific research topics are 
  <ol type="a" start="1">
      <li>restoring and enhancing the images and videos captured in adverse weather (hazy, foggy, sandy, dusty, rainy, snowy day)</li>
      <li>restoring and enhancing the images and videos captured in special circumstances or devices (underwater, weak illumination, dark, under-display devices)</li>
      <li>general photo enhancement, auto image retouching</li>
      <li>image/depth super-resolution, image deblurring, image denosing</li>
  </ol>
  <li><strong>Multi-Modality Scene Understanding</strong> </li><br/>
	  The purpose is to design AI models to perceive and understand scenes. The specific research topics are
  <ol type="a" start="1">
      <li>RGB-D salient object detection</li>
      <li>co-salient object detection</li>
      <li>remote sensing image salient object detection</li>
  </ol>  

  
</ul>
<br> -->
<hr />
</p> 

<!--
<h2>
<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recent News:</h2>
 
<ul>
<li> 2023/10 --3 papers (including one spotlight paper) got accepted by <strong>NeurIPS 2023</strong>.</li>
<li> 2023/09 --Two papers have been recognized as <strong>ESI Hot Paper</strong></li> 

</ul>
<br>
<hr />

-->

<div class="container">
<h2><a id="reaserch-page" class="anchor" href="#reaserch-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Selected Publications:</h2>
        <be>
	
	<div class="publication">
          <img src="logo/shengdanqiu.png" onmouseover="this.src='gifs/doro.gif';" onmouseout="this.src='gifs/doro.gif';" class="publogo"  width="200 px">
	<p>     
	
                <strong>
                    <a href="">Neurips2025_Quant_camery_ready</a>
                </strong>
		  <br> 
		<em><b>Nips, 2025 <a href="" target="_blank"><font color="#ff0000"></font></a></b></em>
                <br> 
              ZhanFeng Feng, Long Peng, Xin Di, Yong Guo, Wenbo Li, Yulun Zhang,Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2505.12266">PDF</a>| 
		                <!-- <a href="htmlTest.html">Project Page</a>|  -->	
                     <!-- È°µÈù¢ÊöÇÊó∂Ê≤°ÂÅö ÁïôÁùÄÊîπ-->
                    <a href="https://github.com/xiaoBIGfeng/PMQ-VE">Code</a>
                </span>
            </p>
          </div>
          <br>
          <br>
	<br>
	<br />
	<br />
	<br />
  <div class="publication">
          <img src="logo/shengdanqiu.png" onmouseover="this.src='gifs/spincat.gif';" onmouseout="this.src='gifs/spincat.gif';" class="publogo"  width="200 px">
	<p>     
	
                <strong>
                    <a href="">Towards realistic data generation for real world super-resolution-ICLR</a>
                </strong>
		  <br> 
		<em><b>AAAI, 2025 <a href="" target="_blank"><font color="#ff0000"></font></a></b></em>
                <br> 
              Long Peng, Wenbo Li, Renjing Pei, Jingjing Ren, Jiaqi Xu, Yang Wang, Yang Cao, Zheng-Jun Zha
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2406.07255">PDF</a>| 
		                <!-- <a href="htmlTest.html">Project Page</a> -->| 	
                    <a href="https://arxiv.org/abs/2406.07255">Code</a>
                    <!-- Ëøô‰∏™Ê≤°ÊâæÂà∞githubÂºÄÊ∫êÈ°πÁõÆ -->
                </span>
            </p>
          </div>
          <br>
          <br>
	<br>
	<br />
	<br />
	<br />
  <div class="publication">
          <img src="logo/shengdanqiu.png" onmouseover="this.src='gifs/runningduck.gif';" onmouseout="this.src='gifs/runningduck.gif';" class="publogo"  width="200 px">
	<p>     
	
                <strong>
                    <a href="">Boosting Image De-Raining via Central-Surrounding Synergistic Convolution-AAA</a>
                </strong>
		  <br> 
		<em><b>ICLR, 2025 <a href="" target="_blank"><font color="#ff0000"></font></a></b></em>
                <br> 
              Long PengÔºåYang WangÔºåXin DiÔºåPeizheXiaÔºåXueyang FuÔºåYang CaoÔºåZheng-Jun Zha
                <br>
                <span class="links">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32693">PDF</a>| 
		               <!--  <a href="htmlTest.html">Project Page</a>| 	 -->
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32693">Code</a>
                    <!-- Ê≤°ÊâæÂà∞githubÂºÄÊ∫êÁöÑ‰ª£Á†ÅÈ°µ -->
                </span>
            </p>
          </div>
          <br>
          <br>
	<br>
	<br />
	<br />
	<br />
	
	
	




<!--
<h2>
<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Events:</h2>  

<div class="publication">
           <img src="./logo/MIPI_2023.png" class="publogo" width="300 px">
            <p> 
                <strong>
                    <a href="">Mobile Intelligent Photography & Imaging</a>
                </strong>
		  <br> 
		<em><b>2nd MIPI workshop @ CVPR 2023</b></em>
                <br> 
              <b>Chongyi Li</b>, Shangchen Zhou, Ruicheng Feng,  Yuekun Dai, Qingpeng Zhu, Qianhui Sun,  Wenxiu Sun,  Chen Change Loy, and Jinwei Gu.
                <br>
                <span class="links">
		      <a href="https://mipi-challenge.org/MIPI2023/">Website</a>	
		      
                </span>
            </p>
          </div>
          <br>
          <br>
	<br />
	<br />

<div class="publication">
            <img src="logo/codeformer1.jpg" onmouseover="this.src='logo/codeformer2.jpg';" onmouseout="this.src='logo/codeformer1.jpg';" class="publogo"  width="300 px">
            <p> 
                <strong>
                    <a href="">Try Your Face (face restoration platform)</a>
                </strong> 
              We provide our code of CodeFormer (Towards Robust Blind Face Restoration with Codebook Lookup TransFormer) on Colab. Please feel free to try your face.
                <br>
                <span class="links">
		      <a href="https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing">Colab</a>	
		      
                </span>
            </p>
          </div>
          <br>
	  <br>
	<br />
	<br />
	<br />
	
<div class="publication">
            <img src="logo/plateform1.jpg" onmouseover="this.src='logo/plateform2.jpg';" onmouseout="this.src='logo/plateform1.jpg';" class="publogo"  width="300 px">
            <p> 
                <strong>
                    <a href="">Low-Light Image Enhancement Online Platform</a>
                </strong> 
              Different algorithms demand various configurations, GPU versions, and hardware specifications that are prohibitive to beginners who are new to this area and may not even have GPU resources. We contribute an online plateform.
                <br>
                <span class="links">
		      <a href="http://mc.nankai.edu.cn/ll/">Website</a>	
		      
                </span>
            </p>
          </div>
          <br>
	  <br>
	<br />
	<br />
	<br />
	
	  <div class="publication">
           <img src="./logo/MIPI.png" class="publogo" width="300 px">
            <p> 
                <strong>
                    <a href="">Mobile Intelligent Photography & Imaging</a>
                </strong>
		  <br> 
		<em><b>1st MIPI workshop @ ECCV 2022</b></em>
                <br> 
              <b>Chongyi Li</b>, Shangchen Zhou, Ruicheng Feng, Jun Jiang, Wenxiu Sun, Qingyu Yang, Qingpeng Zhu, Chen Change Loy, and Jinwei Gu.
                <br>
                <span class="links">
		      <a href="https://mipi-challenge.org/MIPI2022/">Website</a>	
		      
                </span>
            </p>
          </div>
          <br>
          <br>
	<br />
	<br />
	
<ul>
<li><a href="http://mipi-challenge.org/" target="_blank"><font color="#A52A2A">[Workshop]</font></a> ECCV 2022 Workshop on Mobile Intelligent Photography and Imaging (MIPI)</a></li>
<li><a href="https://attend.ieee.org/mmsp-2022/special-sessions/underwater-multimedia-processing/" target="_blank"><font color="#A52A2A">[Special Session]</font></a> IEEE MMSP 2022 Special Session on Underwater Multimedia Processing</a></li>
<li><a href="https://www.frontiersin.org/research-topics/39049/multimodal-intelligence" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Frontiers in Signal Processing Special Issue on Multimodal Intelligence</a></li>
<li><a href="https://ieeeoes.org/wp-content/uploads/2021/07/JOE_cfp_AMLM.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> IEEE Journal of Oceanic Engineering Special Issue on Advanced Machine Learning Methodologies for Underwater Image and Video Processing and Analysis (2021-2022)</a></li>
<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/MTAP_SI_CFP.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Multimedia Tools and Applications Special Issue on Depth-Related Processing and Applications in Visual Systems (2020-2021)</a></li>
<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/SPIC_SI_cfp.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Signal Processing: Image Communication Special Issue on Visual Information Processing for Underwater Images and Videos: Theories, Algorithms, and Applications (2019-2020)</a></li>
<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/APSIPA-ASC-2019-CfP.pdf" target="_blank"><font color="#A52A2A">[Special Session]</font></a> APSIPA ASC 2019 Special Session on Multi-source Data Processing and Analysis: Models, Methods and Applications (2019-2020)</a></li>

</ul>
<br>
<hr />
-->	

		 


		 
<h2>
<a id="reaserch-page" class="anchor" href="#reaserch-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Miscellaneous:</h2>

 
<ul>
<li><a href="https://unsplash.com/"><font color="#1C86EE">Unsplash</font></a></li>
<li><a href="https://pngtree.com/"><font color="#1C86EE">Pngtree</font></a></li>
<li><a href="https://www.wordclouds.com/"><font color="#1C86EE">WordClouds</font></a></li>
<li><a href="https://emojipedia.org/"><font color="#1C86EE">Emojipedia</font></a></li>
<li><a href="https://film-grab.com/"><font color="#1C86EE">FilmGrab</font></a></li>
<li><a href="https://deviparikh.medium.com/how-we-write-rebuttals-dc84742fece1/"><font color="#1C86EE">How we write rebuttals</font></a></li>
<li><a href="http://www-net.cs.umass.edu/kurose/writing/intro-style.html"><font color="#1C86EE">Writing a good introduction</font></a></li>
<li><a href="https://www.computer.org/publications/tech-news/trends/deep-learning-vs-machine-learning-whats-the-difference?source=cssocial"><font color="#1C86EE">Deep Learning vs Machine Learning: What‚Äôs the Difference</font></a></li>
</ul>
<br>


<!--<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=pPHWAkKgmzsFC_v7-3ndOuL5q3qL_EhEE16zTJwxtRw"></script> -->
<!--<div align="center"><a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3244445&c=9733648" alt="AmazingCounters.com"></a></div>--> 
<!--div align="center"><a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3230662&c=9692299" alt="AmazingCounters.com"></a></div>-->
<!-- Global site tag (gtag.js) - Google Analytics -->
<!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156698907-1"></script>-->




</section>

</div>
<!--<script src="javascripts/scale.fix.js"></script>-->
</body>
</html>  